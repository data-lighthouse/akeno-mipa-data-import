{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cb76c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import os\n",
    "from gql import gql\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67d318c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gql import Client\n",
    "from gql.transport.aiohttp import AIOHTTPTransport\n",
    "from gql.transport.httpx import HTTPXTransport\n",
    "\n",
    "\n",
    "class GraphQLClient:\n",
    "    def __init__(self, async_mode: bool = True):\n",
    "        GRAPHQL_ENDPOINT = os.getenv(\n",
    "            \"GRAPHQL_ENDPOINT\", \"http://localhost:8080/v1/graphql\"\n",
    "        )\n",
    "        HASURA_GRAPHQL_ADMIN_SECRET = os.getenv(\n",
    "            \"HASURA_GRAPHQL_ADMIN_SECRET\", \"superdupersecuresecret\"\n",
    "        )\n",
    "        params = {\n",
    "            \"url\": GRAPHQL_ENDPOINT,\n",
    "            \"headers\": {\"x-hasura-admin-secret\": HASURA_GRAPHQL_ADMIN_SECRET},\n",
    "        }\n",
    "\n",
    "        if async_mode:\n",
    "            transport = AIOHTTPTransport(**params)  # type: ignore\n",
    "        else:\n",
    "            transport = HTTPXTransport(**params)  # type: ignore\n",
    "\n",
    "        self.client = Client(transport=transport, fetch_schema_from_transport=True)\n",
    "\n",
    "    def getClient(self):\n",
    "        return self.client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "368a99a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import excel file data.xlsx\n",
    "products = pd.read_excel(\"data.xlsx\", sheet_name=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5469181c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Produkt ID', 'Name', 'Eigene Produktnummer', 'Einheit'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "934c5c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "products.rename(columns={\n",
    "    \"Produkt ID\": \"productId\",\n",
    "    \"Name\": \"name\",\n",
    "    \"Einheit\": \"unit\",\n",
    "}, inplace=True)\n",
    "products[\"externalArticleNumber\"] = products[\"productId\"].astype(str)\n",
    "products[\"productId\"] = products[\"productId\"].astype(str)\n",
    "products[\"name\"] = products[\"name\"].str.strip()\n",
    "products[\"unit\"] = products[\"unit\"].str.strip()\n",
    "products[\"createdAt\"] = datetime.now(timezone.utc).isoformat()\n",
    "products[\"updatedAt\"] = datetime.now(timezone.utc).isoformat()\n",
    "products[\"userId\"] = \"cm6p6u49o0000k9wtbwgfft3h\"\n",
    "products[\"retired\"] = False\n",
    "products[\"name\"] = products[\"name\"].str.replace(r\"\\s{2,}\", \" \", regex=True)\n",
    "products.drop(columns=[\"Eigene Produktnummer\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee69f82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'insert_masterdata_Product': {'affected_rows': 2073}}\n",
      "Inserted 2073 products.\n"
     ]
    }
   ],
   "source": [
    "product_insert_query = gql(\"\"\"\n",
    "mutation MyMutation($objects: [masterdata_Product_insert_input!] = {}) {\n",
    "  insert_masterdata_Product(objects: $objects, on_conflict: {constraint: Product_pkey, update_columns: name}) {\n",
    "    affected_rows\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "client = GraphQLClient(async_mode=False).getClient()\n",
    "with client as session:\n",
    "    result = session.execute(\n",
    "        product_insert_query,\n",
    "        variable_values={\"objects\": products.to_dict(orient=\"records\")},\n",
    "    )\n",
    "    print(result)\n",
    "    print(f\"Inserted {result['insert_masterdata_Product']['affected_rows']} products.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46217fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_df = pd.read_excel(\"data.xlsx\", sheet_name=5)\n",
    "locations_df.rename(columns={\n",
    "    \"Ort ID\": \"locationId\",\n",
    "    \"Name\": \"name\",\n",
    "}, inplace=True)\n",
    "locations_df[\"locationId\"] = locations_df[\"locationId\"].astype(str)\n",
    "locations_df.drop(columns=[\"name\"], inplace=True, errors='ignore')\n",
    "locations_df[\"createdAt\"] = datetime.now(timezone.utc).isoformat()\n",
    "locations_df[\"updatedAt\"] = datetime.now(timezone.utc).isoformat() \n",
    "locations_df[\"userId\"] = \"cm6p6u49o0000k9wtbwgfft3h\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b608a222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'insert_masterdata_Location': {'affected_rows': 2}}\n",
      "Inserted 2 locations.\n"
     ]
    }
   ],
   "source": [
    "locations_query = gql(\"\"\"\n",
    "mutation MyMutation($objects: [masterdata_Location_insert_input!] = {}) {\n",
    "  insert_masterdata_Location(objects: $objects, on_conflict: {constraint: Location_pkey, update_columns: userId}) {\n",
    "    affected_rows\n",
    "    }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "client = GraphQLClient(async_mode=False).getClient()\n",
    "with client as session:\n",
    "    result = session.execute(\n",
    "        locations_query,\n",
    "        variable_values={\"objects\": locations_df.to_dict(orient=\"records\")},\n",
    "    )\n",
    "    print(result)\n",
    "    print(f\"Inserted {result['insert_masterdata_Location']['affected_rows']} locations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "946bfe07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'insert_masterdata_AssetType_one': {'assetTypeId': 'machine'}}\n",
      "Inserted asset type: machine.\n"
     ]
    }
   ],
   "source": [
    "# Insert assetType into database\n",
    "with client as session:\n",
    "    result = session.execute(\n",
    "        gql(\"\"\"mutation MyMutation {\n",
    "            insert_masterdata_AssetType_one(object: {assetTypeId: \"machine\", name: \"machine\", isWorker: false, isStorage: false, isMultiProductStorage: false, fixedPosition: true, createdAt: \"2025-08-15T14:45:00\", userId: \"cm6p6u49o0000k9wtbwgfft3h\", sizeUnit: \"kg\", retired: false, updatedAt: \"2025-08-15T14:45:00\"}) {\n",
    "              assetTypeId\n",
    "            }\n",
    "          }\n",
    "          \"\"\"))\n",
    "    print(result)\n",
    "    print(f\"Inserted asset type: {result['insert_masterdata_AssetType_one']['assetTypeId']}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b137cbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_df = pd.read_excel(\"data.xlsx\", sheet_name=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d08d1652",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_df.rename(columns={\n",
    "    \"Anlagen ID\": \"assetId\",\n",
    "    \"Name\": \"name\",\n",
    "    \"Ort\": \"locationId\"\n",
    "}, inplace=True)\n",
    "\n",
    "assets_df[\"assetTypeId\"] = \"machine\"\n",
    "assets_df[\"assetId\"] = assets_df[\"assetId\"].astype(str)\n",
    "assets_df[\"locationId\"] = assets_df[\"locationId\"].astype(str)\n",
    "assets_df[\"name\"] = assets_df[\"name\"].str.strip()\n",
    "assets_df[\"createdAt\"] = datetime.now(timezone.utc).isoformat()\n",
    "assets_df[\"updatedAt\"] = datetime.now(timezone.utc).isoformat()\n",
    "assets_df[\"userId\"] = \"cm6p6u49o0000k9wtbwgfft3h\"\n",
    "assets_df[\"retired\"] = False\n",
    "assets_df[\"name\"] = assets_df[\"name\"].str.replace(r\"\\s{2,} \", \" \", regex=True)\n",
    "assets_df.drop(columns=[\"Anlagentyp\"], inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "225b2fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'insert_masterdata_Asset': {'affected_rows': 11}}\n",
      "Inserted 11 assets.\n"
     ]
    }
   ],
   "source": [
    "with client as session:\n",
    "    result = session.execute(\n",
    "        gql(\"\"\"\n",
    "        mutation MyMutation($objects: [masterdata_Asset_insert_input!] = {}) {\n",
    "            insert_masterdata_Asset(objects: $objects, on_conflict: {constraint: Asset_pkey, update_columns: name}) {\n",
    "                affected_rows\n",
    "            }\n",
    "        }\n",
    "        \"\"\"),\n",
    "        variable_values={\"objects\": assets_df.to_dict(orient=\"records\")},\n",
    "    )\n",
    "    print(result)\n",
    "    print(f\"Inserted {result['insert_masterdata_Asset']['affected_rows']} assets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7080f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_orders_df = pd.read_excel(\"data.xlsx\", sheet_name=1)\n",
    "production_orders_df.rename(columns={\n",
    "    \"Auftragsnummer\": \"productionOrderId\",\n",
    "    \"Produkt ID\": \"mainProductId\",\n",
    "    \"Batchnummer\": \"number\",\n",
    "    \"Menge\": \"actualQuantity\",\n",
    "    \"Start\": \"actualStart\",\n",
    "    \"Ende\": \"actualEnd\",\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93ec8f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert actualStart and actualEnd from YYYY-MM-DD to datetime object\n",
    "def convert_to_datetime(date_str):\n",
    "    if pd.isna(date_str):\n",
    "        return None\n",
    "    return datetime.strptime(date_str, \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
    "production_orders_df[\"actualStart\"] = production_orders_df[\"actualStart\"].apply(convert_to_datetime)\n",
    "production_orders_df[\"actualEnd\"] = production_orders_df[\"actualEnd\"].apply(convert_to_datetime)\n",
    "\n",
    "# Convert datetime objects to ISO format\n",
    "production_orders_df[\"actualStart\"] = production_orders_df[\"actualStart\"].apply(lambda x: x.isoformat() if x else None)\n",
    "production_orders_df[\"actualEnd\"] = production_orders_df[\"actualEnd\"].apply(lambda x: x.isoformat() if x else None)\n",
    "production_orders_df[\"productionOrderId\"] = production_orders_df[\"productionOrderId\"].astype(str)\n",
    "production_orders_df[\"mainProductId\"] = production_orders_df[\"mainProductId\"].astype(str)\n",
    "production_orders_df[\"number\"] = production_orders_df[\"number\"].astype(str)\n",
    "production_orders_df[\"createdAt\"] = datetime.now(timezone.utc).isoformat()\n",
    "production_orders_df[\"updatedAt\"] = datetime.now(timezone.utc).isoformat()\n",
    "\n",
    "# delete rows with NaN in mainProductId\n",
    "production_orders_df.dropna(subset=[\"mainProductId\"], inplace=True)\n",
    "\n",
    "# set entries with NaN in actualQuantity to 0\n",
    "production_orders_df[\"actualQuantity\"] = production_orders_df[\"actualQuantity\"].fillna(0)\n",
    "\n",
    "# only keep touched columns\n",
    "production_orders_df = production_orders_df[[\n",
    "    \"productionOrderId\",\n",
    "    \"mainProductId\",\n",
    "    \"number\",\n",
    "    \"actualQuantity\",\n",
    "    \"actualStart\",\n",
    "    \"actualEnd\",\n",
    "    \"createdAt\",\n",
    "    \"updatedAt\"\n",
    "]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9050d5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'insert_soe_state_ProductionOrder': {'affected_rows': 15550}}\n",
      "Inserted 15550 production orders.\n"
     ]
    }
   ],
   "source": [
    "production_order_query = gql(\"\"\"\n",
    "                             mutation MyMutation($objects: [soe_state_ProductionOrder_insert_input!] = {}) {\n",
    "  insert_soe_state_ProductionOrder(objects: $objects) {\n",
    "    affected_rows\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "client = GraphQLClient(async_mode=False).getClient()\n",
    "\n",
    "with client as session:\n",
    "    result = session.execute(\n",
    "        production_order_query,\n",
    "        variable_values={\"objects\": production_orders_df.to_dict(orient=\"records\")},\n",
    "    )\n",
    "    print(result)\n",
    "    print(f\"Inserted {result['insert_soe_state_ProductionOrder']['affected_rows']} production orders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e8c1484",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_df = pd.read_excel(\"data.xlsx\", sheet_name=0)\n",
    "tasks_df.rename(columns={\n",
    "    \"Anlage\": \"assetId\",\n",
    "    \"Auftrag\": \"processRecordId\",\n",
    "    \"Start\": \"actualStart\",\n",
    "    \"Ende\": \"actualEnd\",\n",
    "    \"Zustand\": \"name\"\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e73dd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of production orders with no tasks: 7468 which is 48.03% of all production orders.\n"
     ]
    }
   ],
   "source": [
    "# Ensure both keys are of the same type (string)\n",
    "tasks_df[\"processRecordId\"] = tasks_df[\"processRecordId\"].astype(str)\n",
    "production_orders_df[\"productionOrderId\"] = production_orders_df[\"productionOrderId\"].astype(str)\n",
    "\n",
    "# Join the tasks_df on the production_orders_df by processRecordId = productionOrderId\n",
    "merged_production_tasks = tasks_df.merge(\n",
    "    production_orders_df[[\"productionOrderId\", \"mainProductId\"]],\n",
    "    left_on=\"processRecordId\",\n",
    "    right_on=\"productionOrderId\",\n",
    "    how=\"left\"\n",
    ")\n",
    "# count how many production_orders have no tasks\n",
    "no_tasks_count = production_orders_df[~production_orders_df[\"productionOrderId\"].isin(tasks_df[\"processRecordId\"])][\"productionOrderId\"].count()\n",
    "print(f\"Number of production orders with no tasks: {no_tasks_count} which is {no_tasks_count / production_orders_df.shape[0] * 100:.2f}% of all production orders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e1c1ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all rows where productionOrderId is NaN\n",
    "merged_production_tasks.dropna(subset=[\"productionOrderId\"], inplace=True)\n",
    "\n",
    "# only keep rows where name = Rüsten\n",
    "merged_production_tasks = merged_production_tasks[merged_production_tasks[\"name\"] == \"Rüsten\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a63fcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tasks with no production order: 0 which is 0.00% of all tasks.\n"
     ]
    }
   ],
   "source": [
    "# Count how many tasks have no production order after joining them\n",
    "no_production_order_tasks_count = merged_production_tasks[merged_production_tasks[\"productionOrderId\"].isna()][\"processRecordId\"].count()\n",
    "print(f\"Number of tasks with no production order: {no_production_order_tasks_count} which is {no_production_order_tasks_count / tasks_df.shape[0] * 100:.2f}% of all tasks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481537ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in amount column: 0 which is 0.00% of all inventory records.\n",
      "{'insert_soe_state_inventory': {'affected_rows': 21668}}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'insert_soe_state_Inventory'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 73\u001b[39m\n\u001b[32m     67\u001b[39m result = session.execute(\n\u001b[32m     68\u001b[39m     inventory_query,\n\u001b[32m     69\u001b[39m     variable_values={\u001b[33m\"\u001b[39m\u001b[33mobjects\u001b[39m\u001b[33m\"\u001b[39m: inventory_objects},\n\u001b[32m     70\u001b[39m )\n\u001b[32m     71\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[32m     72\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInserted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minsert_soe_state_Inventory\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[33m'\u001b[39m\u001b[33maffected_rows\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m inventory records.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m )\n",
      "\u001b[31mKeyError\u001b[39m: 'insert_soe_state_Inventory'"
     ]
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "inventory_df = pd.read_excel(\"data.xlsx\", sheet_name=3)\n",
    "inventory_df.rename(\n",
    "    columns={\n",
    "        \"Produkt ID\": \"productId\",\n",
    "        \"Menge\": \"amount\",\n",
    "        \"Ort\": \"locationId\",\n",
    "        \"Batchnummer\": \"productionOrderNumber\",\n",
    "        # \"Auftragsnummer\": \"productionOrderId\",\n",
    "        \"Letzte Aktualisierung\": \"updatedAt\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "inventory_df[\"productId\"] = inventory_df[\"productId\"].astype(str)\n",
    "# drop rows with na in productId or amount\n",
    "inventory_df.dropna(subset=[\"productId\", \"amount\"], inplace=True)\n",
    "inventory_df[\"locationId\"] = inventory_df[\"locationId\"].astype(str)\n",
    "inventory_df[\"updatedAt\"] = inventory_df[\"updatedAt\"].apply(convert_to_datetime)\n",
    "inventory_df[\"updatedAt\"] = inventory_df[\"updatedAt\"].apply(\n",
    "    lambda x: x.isoformat() if x else None\n",
    ")\n",
    "# inventory_df[\"updatedAt\"] = datetime.now(timezone.utc).isoformat()\n",
    "inventory_df[\"updatedBy\"] = \"cm6p6u49o0000k9wtbwgfft3h\"\n",
    "inventory_df[\"inventoryId\"] = inventory_df.apply(\n",
    "    lambda row: str(uuid4()), axis=1\n",
    ")  # Generate a unique inventoryId for each row\n",
    "\n",
    "# set unit statically to pcs\n",
    "inventory_df[\"unit\"] = \"pcs\"\n",
    "\n",
    "# drop Auftragsnummer column\n",
    "inventory_df.drop(columns=[\"Auftragsnummer\"], inplace=True, errors='ignore')\n",
    "\n",
    "# convert to list of dict\n",
    "inventory_objects = inventory_df.to_dict(orient=\"records\")\n",
    "\n",
    "# run through the inventory objects and delete all attributes from each dict if it is none\n",
    "for obj in inventory_objects:\n",
    "    keys_to_delete = [\n",
    "        key\n",
    "        for key, value in obj.items()\n",
    "        if value is None\n",
    "        or (isinstance(value, float) and pd.isna(value))\n",
    "        or (isinstance(value, str) and value.strip() == \"\")\n",
    "        or (isinstance(value, str) and value == 'NaT')  # Also remove zero values\n",
    "    ]\n",
    "    for key in keys_to_delete:\n",
    "        del obj[key]\n",
    "\n",
    "# count all nan values in the amount column\n",
    "nan_amount_count = inventory_df[\"amount\"].isna().sum()\n",
    "print(\n",
    "    f\"Number of NaN values in amount column: {nan_amount_count} which is {nan_amount_count / inventory_df.shape[0] * 100:.2f}% of all inventory records.\"\n",
    ")\n",
    "\n",
    "inventory_query = gql(\"\"\"\n",
    "mutation MyMutation($objects: [soe_state_inventory_insert_input!] = {}) {\n",
    "  insert_soe_state_inventory(objects: $objects, on_conflict: {constraint: inventory_pkey, update_columns: amount}) {\n",
    "    affected_rows\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# Execute the inventory query\n",
    "with client as session:\n",
    "    result = session.execute(\n",
    "        inventory_query,\n",
    "        variable_values={\"objects\": inventory_objects},\n",
    "    )\n",
    "    print(result)\n",
    "    print(\n",
    "        f\"Inserted {result['insert_soe_state_inventory']['affected_rows']} inventory records.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a835192d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'insert_soe_state_demand': {'affected_rows': 1161}}\n",
      "Inserted 1161 demand records.\n"
     ]
    }
   ],
   "source": [
    "demand_df = pd.read_excel(\"data.xlsx\", sheet_name=2)\n",
    "demand_df.rename(columns={\n",
    "    \"Produkt ID\": \"productId\",\n",
    "    \"Menge\": \"amount\",\n",
    "    \"Benötigte Fertigstellung Produktion\": \"confirmedDueDate\",\n",
    "    \"Auftragsnummer\": \"orderId\",\n",
    "}, inplace=True)\n",
    "\n",
    "# statically set the unit to pcs\n",
    "demand_df[\"unit\"] = \"pcs\"\n",
    "demand_df[\"productId\"] = demand_df[\"productId\"].astype(str)\n",
    "demand_df[\"orderId\"] = demand_df[\"orderId\"].astype(str)\n",
    "# convert confirmedDueDate to pd.Timestamp\n",
    "demand_df[\"confirmedDueDate\"] = pd.to_datetime(demand_df[\"confirmedDueDate\"], errors='coerce')\n",
    "# dump to ISO format\n",
    "demand_df[\"confirmedDueDate\"] = demand_df[\"confirmedDueDate\"].apply(\n",
    "    lambda x: x.isoformat() if pd.notna(x) else None\n",
    ")\n",
    "demand_df[\"createdAt\"] = datetime.now(timezone.utc).isoformat()\n",
    "demand_df[\"updatedAt\"] = datetime.now(timezone.utc).isoformat()\n",
    "demand_df[\"createdBy\"] = \"cm6p6u49o0000k9wtbwgfft3h\"\n",
    "demand_df[\"demandId\"] = demand_df.apply(\n",
    "    lambda row: str(uuid4()), axis=1\n",
    ")  # Generate a unique demandId for each row\n",
    "# drop column Produktionsauftragsnummer\n",
    "demand_df.drop(columns=[\"Produktionsauftragsnummer\"], inplace=True, errors='ignore')\n",
    "# drop column MTO/MTS\n",
    "demand_df.drop(columns=[\"MTO/MTS\"], inplace=True, errors='ignore')\n",
    "# statically set the locationId to ESS\n",
    "demand_df[\"locationId\"] = \"ESS\"\n",
    "\n",
    "# convert to list of dict\n",
    "demand_objects = demand_df.to_dict(orient=\"records\")\n",
    "\n",
    "demand_query = gql(\"\"\"\n",
    "mutation MyMutation($objects: [soe_state_demand_insert_input!] = {}) {\n",
    "  insert_soe_state_demand(objects: $objects, on_conflict: {constraint: demand_pkey, update_columns: amount}) {\n",
    "    affected_rows\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# Execute the demand query\n",
    "with client as session:\n",
    "    result = session.execute(\n",
    "        demand_query,\n",
    "        variable_values={\"objects\": demand_objects},\n",
    "    )\n",
    "    print(result)\n",
    "    print(f\"Inserted {result['insert_soe_state_demand']['affected_rows']} demand records.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "akeno-mipa-dataImport",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
